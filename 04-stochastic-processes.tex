\lecture{Случайные функции}
\section{Общие положения}
Скалярная или векторная функция одной или нескольких переменных называется
случайной, если её значения при произвольной последовательности выбора значений
аргументов являются набором случайных величин. Случайная функция времени
называется случайным процессом, а случайная функция координат (и, быть может,
времени) -- случайным полем.

Случайные процессы делятся на два класса:
\begin{itemize}
    \item с дискретным временем -- случайные последовательности;
    \item с непрерывным временем.
\end{itemize}

Примером случайного процесса может служить броуновское движение. В каждый момент
времени такой процесс характеризуется одномерной плотностью вероятности
\( w_t(x) \). Она даёт представление о процессе лишь в данный момент времени.

Для случайного процесса можно ввести функцию распределения:
\[
    F(x_1, \ldots, x_n; t_1, \ldots, t_n) =
        P(X(t_1) \le x_1, \ldots, X(t_n) \le x_n).
\]

Она имеет два свойства:
\begin{enumerate}
    \item симметричность -- функция распределения инвариантна относительно
        одновременной перестановки \( x_m \) и \( x_k \) и соответствующих
        им моментов времени \( t_m \) и \( t_k \);
    \item согласованность.
\end{enumerate}

Условная функция распределения:
\[
    v(\mathbf{x_1};\mathbf{t_1}|\mathbf{x_2};\mathbf{t_2}) =
    P(\mathbf{x}(\mathbf{t_1})\in[\mathbf{x_1}+\mathbf{dx_1}]|
        \mathbf{x}(\mathbf{t_2})=\mathbf{x_2}).
\]

Плотностью вероятности случайного процесса называется величина
\[
    w(x_1;t_1) = \der{F(x_1;t_1)}{x_1},\quad
    w(x_1,x_2;t_1,t_2) = \frac{d^2F(x_1,x_2;t_1,t_2)}{dx_1 dx_2}.
\]
Она обладает теми же двумя свойствами, что и функция распределения --
симметричностью и согласованностью.

Для случайного процесса можно ввести характеристическую функцию:
\[
    \theta(u_1;t_1) = \average{e^{iu_1x_1}},\quad
    \theta(\mathbf{u};\mathbf{t}) = \average{e^{i\mathbf{u}\cdot\mathbf{x}}}.
\]

Кумулянты
\[
    \kappa_{k_1,\ldots,k_n} = (-1)^n\frac{\partial^N\ln\theta_n}
    {\partial u_1^{k_1} \ldots \partial u_n^{k_n}}.
\]

Ещё можно ввести моментные функции
\[
    m_{k_1,k_2,\ldots,k_n} = \average{x_1^{k_1}\cdot\ldots\cdot x_n^{k_n}}.
\]

Центральный смешанный момент второго порядка называется коэффициентом
автокорреляции:
\[
    B(t_1, t_2) = \average{[x(t_1) - \average{x(t_1)}]\cdot
    [x(t_2) - \average{x(t_2)}]} = K(t_1,t_2).
\]
При \( t_1 = t_2 = t \) \( B(t_1, t_2) = \sigma^2(t) \).

Коэффициент корреляции
\[
    r(t_1, t_2) = \frac{B(t_1,t_2)}{\sigma(t_1)\sigma(t_2)}.
\]
Если \( x(t1) \) и \( x(t_2) \) связаны линейно, то \( r(t_1, t_2) = \pm 1 \).

Ну и, наконец, время корреляции
\[
    \tau_0(t_1) = \int_0^\infty B(t_1,t_2) dt_2.
\]
Оно даёт ориентировочные представления о интервале времени, на котором имеет
место коррелированность значений.

\section{Свойства автокорреляционной функции}
\begin{enumerate}
    \item для статистически независимых процессов она равна нулю;
    \item симметрична относительно замены переменных;
    \item ограничена, причём максимум достигается при \( t_1 = t_2 \);
    \item положительно определена:
        \( \ds
        \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}f(t_1)f(t_2)B(t_1,t_2)
        dt_1 dt_2 \ge 0 \).
\end{enumerate}

Взаимной функцией корреляции называется
\[
    B_{xy}(t1,t2) = \average{[x(t_1) - \average{x(t_1)}]\cdot
    [y(t_2) - \average{y(t_2)}]}.
\]

Из двух действительных случайных величин X и Y можно построить комплексную
случайную величину \( Z = X + iY \), которую можно рассматривать как линейную
комбинацию. Для неё функция автокорелляции определяется следующим образом
\[
    B_z(t_1, t_2) = \average{[z(t_1) - \average{z(t_1)}]\cdot
    [z(t_2) - \average{z(t_2)}]^*} =
    B_x(t_1, t_2) + B_y(t_1,t_2) - iB_{xy}(t_1, t_2) + iB_{yx}(t_1,t_2).
\]

Свойства функции автокорреляции комплексной случайной величины с нулевым
математическим ожиданием:
\begin{enumerate}
    \item \( \sigma^2 \ge 0 \);
    \item \( B(t_1,t_2) = B^*(t_2,t_1) \);
    \item \( \ds \abs{B(t_1,t_2)} \le \frac{\average{\abs{z_1}^2} +
        \average{\abs{z_2}^2}}{2} \).
\end{enumerate}

\section{Стационарность и эргодичность случайных процессов}
Случайный процесс стационарен в узком смысле, если для произвольной
последовательности \( \{t_n\} \) и для любого целого числа \( n \)  функция
распределения \( n \)-го порядка удовлетворяет условию
\[
    \forall t_0:
    F(x_1,\ldots,x_n;t_1,\ldots,t_n) = F(x_1,\ldots,x_n;t_1+t_0,\ldots,t_n+t_0).
\]
При этом
\[
    w(x,t) = w(x),\quad \theta(u,t) = \theta(u),\quad F_1(x;t) = F_1(x),\quad
    F_2(x_1,x_2;t_1,t_2) = F_2(x_1,x_2;t_2-t_1).
\]
Поскольку одномерная функция не зависит от времени, то и моменты от времени
зависеть не будут. Двумерная функция зависит от промежутка времени, поэтому
автокорреляционная функция тоже зависит только от промежутка времени:
\( B(t_1,t_2) = B(t_2-t_1) \).

Стационарный процесс в широком смысле (по Хинчину) -- это процесс,
автокорреляция которого зависит только от промежутка времени \( t_2 - t_1 \),
конечна при \( t_2 = t_1 \), а средние значения не зависят от времени.

Стационарный в узком смысле процесс называется эргодическим, если любая
характеристика, полученная учреднением по ансамблю Гиббса, с вероятностью сколь
угодно близкой к 1 равна среднему по времени. Из эквивалентности двух способов
усреднения следует, что для определения вероятностных характеристик случайного
процесса нет необходимости изучать ансамбль Гиббса, а достаточно
продолжительного наблюдения за одной системой.

Условие эргодичности записывается в виде
\[
    \average{x(t)}_T = \frac{1}{T}\int_t^{t+T} x(\tau)d\tau \to[T\to\infty]
    \average{x(t)} = \int_{-\infty}^{+\infty} x(t)w(x)dx.
\]
Можно показать, что необходимым условием эргодичности является
\(\ds \lim_{\tau\to\infty}B(\tau)~=~0 \).

Если для двух процессов \( B_{xy}(t_1,t_2) = B_{xy}(t_2-t_1) \), то такие
процессы называют стационарно связанными.

Корреляционные функции процессов являются предметом исследования корреляционной
теории процессов.

\section{Спектральная плотность интенсивности случайных процессов}
Рассмотрим случайный процесс с нулевым математическим ожиданием. Для него можно
ввести спектральную плотность интенсивности следующим образом:
\[
    G(\omega) = \int_{-\infty}^{+\infty} B(\tau)e^{-i\omega\tau}d\tau.
\]
Обратным преобразованием Фурье получаем автокорреляционную функцию:
\[
    B(\tau) =
        \frac{1}{2\pi}\int_{-\infty}^{+\infty} G(\omega)e^{i\omega\tau}d\omega.
\]
Отсюда
\[
    \sigma^2 = B(0) = \frac{1}{2\pi}\int_{-\infty}^{+\infty} G(\omega)d\omega.
\]

Для вещественных процессов \( G(\omega): \mathbb{R}\to\mathbb{R} \) обладает
свойством чётности \( G(\omega) = G(-\omega) \). Так как она чисто вещественная,
то можно смело применять косинус-преобразование Фурье:
\[
    G(\omega) = 2\int_0^{+\infty} B(\tau)\cos\omega\tau d\tau,\quad
    B(\tau) =
        \frac{1}{\pi}\int_{-\infty}^{+\infty} G(\omega) \cos\omega\tau d\omega,
\]
а так как она чётная, то можно определить функцию неорицательных частот
\( G^+(\omega) = G(\omega) + G(-\omega) \),  для которой
\[
    G^+(\omega) = 4\int_0^{+\infty} B(\tau)\cos\omega\tau d\tau,\quad
    B(\tau) =
        \frac{1}{\pi}\int_0^{+\infty} G^+(\omega) \cos\omega\tau d\omega.
\]
Ширина спектра определяется выражением
\[
    \Delta\omega =
        \frac{\int_{-\infty}^{+\infty}G(\omega)d\omega}{\max(G(\omega))}.
\]

Свойства:
\begin{enumerate}
    \item неотрицательная чётная функция;
    \item убывает в бесконечность быстрее \( 1/\omega \);
    \item \( \ds \tau\Delta\omega = \frac{\pi G(0)}{2\max(G(\omega))} \).
\end{enumerate}

Если все процессы ансамбля Гиббса финитны, то
\[
    x(t) = \int_{-\infty}^{+\infty}S(\omega)e^{i\omega t}d\omega,\quad
    S(\omega) = \frac{1}{2\pi}\int_{-\infty}^{+\infty}x(t)e^{-i\omega t}dt,
\]
где \( S(\omega) \) -- спектр ансамбля Гиббса.

\section{Белый шум}
Случайный процесс, для которого спектральная плотность постоянна, называется
белым шумом. Он является моделью абсолютно случайного процесса, когда средние
значения в два несовпадающих момента времени статистически независимы, а
интегральная ширина энергетического спектра стремится к бесконечности. Многие
процессы в рассматриваемых интервалах частот имеют спектр очень близкий к
равномерному, поэтому их можно аппроксимировать белым шумом.

Математически белый шум выглядит так:
\[
    B(\tau) = G_0\delta(\tau),\quad G(\omega) = G_0.
\]

Если автокорреляционная функция процесса отлична от нуля на узком интервале
\( \tau_0 \), то на частотах \( \omega \ll 1/\tau_0 \) его можно считать белым
шумом.

Стоит отметить, что понятие белый шум характеризует спектр, а не закон
распределения. Обычно белый шум считают центрированным нормальным процессом.

\section{Статистические характеристики производной случайного процесса}
Для гладких функций \( \xi(t) \) по определению
\( \average{\dot{\xi}} = \dot{\average{\xi}} \).
\[
    B_{\xi'}(t_1, t_2) = \average{\xi'(t_1){\xi'}^*(t_2)} =
        \pcder{B_\xi}{t_1}{t_2}
\]
\[
    B_{\xi\xi'}(t_1, t_2) = \average{\xi(t_1){\xi'}^*(t_2)} =
        \pder{B_\xi}{t_2}
\]
Для стационарных процессов:
\[
    B_{\xi'}(\tau) = -\ppder{B_\xi}{\tau},\quad
    G_{\xi'}(\omega) = \omega^2 G_\xi(\omega),\quad
    B_{\xi\xi'}(\tau) = -\pder{B_\xi(\tau)}{\tau},\quad
    G_{\xi\xi'}(\omega) = i\omega G_\xi(\omega).
\]
Для высших производных
\[
    B_{\xi^{(n)}}(t_1, t_2) =
        \frac{\partial^{2n} B_\xi(t_1, t_2)}{\partial^n t_1 \partial^n t_2},
        \quad
    B_{\xi^{(k)}\xi^{(l)}}(t_1, t_2) =
        \frac{\partial^{k+l} B_\xi(t_1, t_2)}{\partial^k t_1 \partial^l t_2}.
\]

\section{Нормальные случайные процессы}
Нормальный случайный процесс -- процесс, одномерная плотность вероятности
которого описывается гауссовой кривой.

Что самое характерное, линейная комбинация нескольких НСП тоже является НСП.

\section{Импульсные случайные процессы}
Импульсный случайный процесс -- это последовательность одиночных импульсов,
амплитуда, длительность, время появления и форма которых могут быть случайными
величинами.
