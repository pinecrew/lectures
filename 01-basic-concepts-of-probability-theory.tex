\section{Основные понятия теории вероятностей}
\subsection{Предмет статистической радиофизики}

Статистическая радиофизика изучает случайные явления в радиофизике.
Статистическое описание является наиболее подходящим для многих электромагнитных
явлений. Статистическая радиофизика изучает случайные процессы на всех этапах
радиосвязи.

Статистическая радиофизика использует методы радиофизики, статистической физики
и теории вероятностей и работает с информационными характеристиками (дисперсией,
корелляцией, \ldots).

Под сообщением понимаются любые данные или сведения, подлежащие передаче. По
своей природе сообщения делятся на механические, тепловые, электромагнитные и
т.д. Сообщения неэлектрической природы часто преобразуют в электрический сигнал
при помощи преобразователей. При необходимости, электрический сигнал для
передачи преобразуют в радиосигнал.

При преобразовании, передаче, распространении и приёме сигнал подвергается
искажениям. Они обуславливаются:
\begin{enumerate}
    \item внешними и внутренними помехами;
    \item распространением сигнала через турбулентную среду;
    \item техническим несовершенством устройств.
\end{enumerate}
Любые нежелательные возмущения, накладывающиеся на сигнал, называются шумом.

\subsection{Вероятность}

Основное понятие радиофизики -- случайная величина. Случайная величина -- это
форма представления заранее не предсказуемых результатов опыта. Для описания
случайных величин в математике вводится понятие вероятности.

Вероятность события \( A \) есть отношение числа опытов, в которых происходило
это событие, к общему числу опытов при стремлении числа опытов к бесконечности:
\[
    P(A) = \lim_{N\to\infty}\frac{N_A}{N}.
\]

Если событие не может произойти ни в одном опыте, то вероятность такого события
равна нулю, а событие называется невозможным.

Если же событие происходит в каждом опыте, то его вероятность равна единице, а
само событие называется достоверным.

Если два события никогда не происходят вместе, то такие события называются
несовместимыми.

Событие, представляющее собой множество вероятных исходов составляет группу
событий. Группа называется полной, если в результате опыта произойдет одно из
событий этой группы.

Два события, образующие полную группу, называются противоположными, если они
несовместимы.

Если всякий раз, когда происходит событие \( A \), происходит событие \( B \),
то говорят, что \( A \) влечет за собой \( B \): \( A \subset B \). Если
\( A \subset B \) и \( B \subset A \), то \( A = B \) и такие события называют
равносильными или эквивалентными.

Событие \( A \) называется статистически зависимым от события \( B \), если
\( P(A) \) зависит от того, осуществилось ли событие \( B \) или нет. В случае
статистической зависимости можно ввести условную вероятность \( P(A|B) \)
события \( A \) при осуществлении события \( B \). Безусловные вероятности
называются априорными, а условные -- апостериорными.

Произведением событий называется такое событие, которое происходит, когда
одновременно происходят все эти события:
\[
    P(AB) = P(A) \cdot P(B|A) = P(B) \cdot P(A|B).
\]

Суммой событий называется событие, которое происходит тогда и только тогда,
когда происходит хотя бы одно из этих событий:
\[
    P(A+B) = P(A) + P(B) - P(AB).
\]

Если события несовместимы и образуют полную группу, то
\[
    P(\sum A_i) = \sum P(A_i) = 1.
\]
Это условие называется условием нормировки.

Пусть несовместимые события \( B \) и \( C \) входят в полную группу, а \( A \)
может произойти только при наступлении этих двух событий, тогда
\[
    P(A) = P(AB) + P(AC) = P(B) \cdot P(A|B) + P(C) \cdot P(A|C).
\]
Эта формула называется формулой полной вероятности.
\[
    P(B|A) = \frac{P(AB)}{P(A)} = \frac{P(B) \cdot P(A|B)}
    {P(B) \cdot P(A|B) + P(C) \cdot P(A|C)} \text{ -- формула Байеса.}
\]

В технике используются системы, состоящие из нескольких элементов. Надежностью
системы называют вероятность того, что система будет работать без отказа в
течение установленного промежутка времени. Пусть система состоит из двух
элементов, причем надежность первого \( P_1 \), а второго \( P_2 \). Тогда
надежность при последовательном соединении равна \( P_1P_2 \),  а при
параллельном -- \( 1 - (1 - P_1)(1 - P_2) = P_1 + P_2 - P_1P_2 \).

